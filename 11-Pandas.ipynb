{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "强⼤⽽灵活的数据分析⼯具,提供了易于使⽤的数据结构和数据分析⼯具,特别适合处理表格型数据（如 Excel 表格、数据库表等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas库的常用方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这些方法都是直接通过 pandas 库调用的，它们不特定于 DataFrame 对象，尽管某些方法（如 pd.concat() 和 pd.merge()）经常与 DataFrame 一起使用。\n",
    "1. 数据类型转换\n",
    "pd.to_numeric(): 将输入转换为数值类型。\n",
    "pd.to_datetime(): 将输入转换为日期时间对象。\n",
    "pd.to_timedelta(): 将输入转换为时间间隔（timedelta）对象。\n",
    "pd.factorize(): 将输入转换为分类类型或整数编码。\n",
    "2. 数据创建\n",
    "pd.Series(): 创建一个 Series 对象。\n",
    "pd.DataFrame(): 创建一个 DataFrame 对象。\n",
    "pd.date_range(): 生成一个日期范围的索引。\n",
    "pd.period_range(): 生成一个周期范围的索引。\n",
    "pd.interval_range(): 生成一个间隔范围的索引。\n",
    "pd.Index(): 创建一个索引对象。\n",
    "3. 数据读取\n",
    "pd.read_csv(): 从 CSV 文件中读取数据。\n",
    "pd.read_excel(): 从 Excel 文件中读取数据。\n",
    "pd.read_sql(): 从 SQL 数据库中读取数据。\n",
    "pd.read_json(): 从 JSON 文件中读取数据。\n",
    "pd.read_html(): 从 HTML 文件中读取表格数据。\n",
    "4. 数据写入\n",
    "pd.DataFrame.to_csv(): 将 DataFrame 写入 CSV 文件。\n",
    "pd.DataFrame.to_excel(): 将 DataFrame 写入 Excel 文件。\n",
    "pd.DataFrame.to_sql(): 将 DataFrame 写入 SQL 数据库。\n",
    "pd.DataFrame.to_json(): 将 DataFrame 写入 JSON 文件。\n",
    "5. 数据合并\n",
    "pd.concat(): 沿着一个轴将多个 pandas 对象连接在一起。\n",
    "pd.merge(): 根据一个或多个键将不同 pandas 对象中的行连接起来。\n",
    "6. 数据处理\n",
    "pd.cut(): 将数据分割成离散的区间。\n",
    "pd.qcut(): 根据分位数将数据分割成离散的区间。\n",
    "pd.get_dummies(): 将分类变量转换为虚拟/指示变量。\n",
    "7. 数据聚合\n",
    "pd.Grouper(): 用于分组操作的帮助器。\n",
    "pd.eval(): 使用字符串表达式进行快速计算。\n",
    "pd.pandas.eval(): 在 DataFrame 上进行字符串表达式计算。\n",
    "8. 窗口函数\n",
    "pd.rolling_window(): 为时间序列数据提供滚动窗口计算。\n",
    "pd.expanding_window(): 为时间序列数据提供扩展窗口计算。\n",
    "pd.ewm(): 提供指数加权移动平均计算。\n",
    "9. 其他\n",
    "pd.isnull(): 检测缺失值。\n",
    "pd.notnull(): 检测非缺失值。\n",
    "pd.isna(): 检测缺失值。\n",
    "pd.notna(): 检测非缺失值。\n",
    "pd.unique(): 返回输入数组中的唯一值。\n",
    "pd.value_counts(): 计算数组中值的频率。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⼀维数据结构 Series \n",
    " 类似表格中的一个列（column）,这个列有每个元素的index值,但没有列名（和dataframe对比）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    10\n",
      "b    20\n",
      "c    30\n",
      "d    40\n",
      "dtype: int64\n",
      "--------------\n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n",
      "--------------\n",
      "a    10\n",
      "b    20\n",
      "c    30\n",
      "d    40\n",
      "dtype: int64\n",
      "--------------\n",
      "s1['a']: 10\n",
      "s3['b']: 20\n",
      "30\n",
      "--------------\n",
      "b    20\n",
      "c    30\n",
      "dtype: int64\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# 创建Series \n",
    "\n",
    "# 从列表创建 Series ,指定了index\n",
    "s1 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "# 没有指定index,则自动生成0,1,2序列\n",
    "s2=pd.Series([10, 20, 30, 40])\n",
    "# 从键值对类型数据结构(如字典)创建 \n",
    "s3 = pd.Series({'a': 10, 'b': 20, 'c': 30, 'd': 40})\n",
    "print(s1)\n",
    "print('--------------')\n",
    "print(s2)\n",
    "print('--------------')\n",
    "print(s3)\n",
    "print('--------------')\n",
    "\n",
    "\n",
    "# Series 的访问\n",
    "\n",
    "# 用index值访问\n",
    "print(\"s1['a']:\", s1['a'])\n",
    "print(\"s3['b']:\", s3['b'])\n",
    "# 用序号访问\n",
    "# print(s1[2]) 这个用法在未来会淘汰,尽量使用loc和iloc索引和切片\n",
    "print(s1.iloc[2])\n",
    "print('--------------')\n",
    "# 切片和list和numpy类似\n",
    "s4 = s3.iloc[1:3]  # 获取索引为1到2的值\n",
    "print(s4)\n",
    "print('--------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    10\n",
      "b     2\n",
      "c     3\n",
      "d     4\n",
      "e     5\n",
      "dtype: int64\n",
      "--------------\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n",
      "--------------\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n",
      "--------------\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Series 的基本操作\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# 添加元素和赋值\n",
    "# 为特定的索引标签赋值\n",
    "s['a'] = 10  # 将索引标签 'a' 对应的元素修改为 10\n",
    "# 通过赋值给新的索引标签来添加元素\n",
    "s['e'] = 5  # 在 Series 中添加一个新的元素,索引标签为 'e'\n",
    "print(s)\n",
    "print('--------------')\n",
    "\n",
    "# 删除元素\n",
    "# 使用 del 删除指定索引标签的元素。\n",
    "del s['a']  # 删除索引标签 'a' 对应的元素\n",
    "print(s)\n",
    "print('--------------')\n",
    "\n",
    "\n",
    "# 使用 drop 方法删除一个或多个索引标签，并返回一个新的 Series。\n",
    "s_dropped = s.drop(['b'])  # 返回一个删除了索引标签 'b' 的新 Series,原s的数据不会修改\n",
    "print(s)\n",
    "print('--------------')\n",
    "s.drop(['b'],inplace=True) #直接在s上操作\n",
    "print(s)\n",
    "print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "--------------\n",
      "[10 20 30 40]\n",
      "--------------\n",
      "int64\n",
      "--------------\n",
      "(4,)\n",
      "--------------\n",
      "4\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Series 的属性\n",
    "print(s1.index)   # 索引\n",
    "print('--------------')\n",
    "print(s1.values)  # 数据\n",
    "print('--------------')\n",
    "print(s1.dtype)   # 数据类型\n",
    "print('--------------')\n",
    "print(s1.shape)   # 形状\n",
    "print('--------------')\n",
    "print(s1.size)    # 元素个数\n",
    "print('--------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "a   NaN\n",
      "b   NaN\n",
      "c   NaN\n",
      "d   NaN\n",
      "dtype: float64\n",
      "--------------\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "dtype: bool\n",
      "--------------\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Series 的+-*/ ><\n",
    "\n",
    "series = pd.Series([1, 2, 3, 4])\n",
    "series1 = pd.Series([2, 3, 4, 5],index=['a','b','c','d'])\n",
    "print(series+series1)\n",
    "print('--------------')\n",
    "# print(series-series1)\n",
    "# print(series*series1)\n",
    "# print(series/series1)\n",
    "# pandas会将索引相同的元素进行+-*/操作,如果所有索引都不一样,则每一列都是空值\n",
    "\n",
    "print(series>2) #和numpy类似,会直接返回一个类型为bool的series\n",
    "print('--------------')\n",
    "ss=series>2\n",
    "# bool索引 pandas和numpy在这些地方很互通\n",
    "print(series[ss])\n",
    "print('--------------')\n",
    "# 过滤\n",
    "filtered_series = series[series > 2]  # 选择大于2的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "3    8\n",
      "dtype: int64\n",
      "--------------\n",
      "0    1.000000\n",
      "1    1.414214\n",
      "2    1.732051\n",
      "3    2.000000\n",
      "dtype: float64\n",
      "--------------\n",
      "10\n",
      "2.5\n",
      "4\n",
      "1\n",
      "1.2909944487358056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 算术运算\n",
    "result = series * 2  # 所有元素乘以2\n",
    "print(result)\n",
    "print('--------------')\n",
    "# 数学函数\n",
    "import numpy as np\n",
    "result = np.sqrt(series)  # 对每个元素取平方根\n",
    "print(result)\n",
    "print('--------------')\n",
    "#统计函数\n",
    "print(series.sum())  # 输出 Series 的总和\n",
    "print(series.mean())  # 输出 Series 的平均值\n",
    "print(series.max())  # 输出 Series 的最大值\n",
    "print(series.min())  # 输出 Series 的最小值\n",
    "print(series.std())  # 输出 Series 的标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9.000000\n",
      "mean     5.000000\n",
      "std      2.738613\n",
      "min      1.000000\n",
      "25%      3.000000\n",
      "50%      5.000000\n",
      "75%      7.000000\n",
      "max      9.000000\n",
      "dtype: float64\n",
      "--------------\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "--------------\n",
      "4    5\n",
      "5    6\n",
      "6    7\n",
      "7    8\n",
      "8    9\n",
      "dtype: int64\n",
      "--------------\n",
      "45\n",
      "5.0\n",
      "2.7386127875258306\n",
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#其他方法\n",
    "s=pd.Series(range(1,10))\n",
    "# 获取描述统计信息\n",
    "print(s.describe())\n",
    "print('--------------')\n",
    "# 获取最大值和最小值的索引\n",
    "max_index = s.idxmax()\n",
    "min_index = s.idxmin()\n",
    "\n",
    "print(s.head())  # 前几个元素，默认是前 5 个\n",
    "print('--------------')\n",
    "print(s.tail())  # 后几个元素，默认是后 5 个\n",
    "print('--------------')\n",
    "print(s.sum())   # 求和\n",
    "print(s.mean())  # 平均值\n",
    "print(s.std())   # 标准差\n",
    "print(s.min())   # 最小值\n",
    "print(s.max())   # 最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维数据结构Dataframe\n",
    "\n",
    "DataFrame 用于表示二维表格型数据。\n",
    "\n",
    "DataFrame 是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔型值）。\n",
    "\n",
    "DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（每个Series共同用一个列索引）。\n",
    "\n",
    "DataFrame 提供了各种功能来进行数据访问、筛选、分割、合并、重塑、聚合以及转换等操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame的创建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Site  Age\n",
      "0  Google   10\n",
      "1  Runoob   12\n",
      "2    Wiki   13\n",
      "--------------\n",
      "     Site  Age\n",
      "0  Google   10\n",
      "1  Runoob   12\n",
      "2    Wiki   13\n",
      "--------------\n",
      "     Site Age\n",
      "0  Google  10\n",
      "1  Runoob  12\n",
      "2    Wiki  13\n",
      "--------------\n",
      "      Name   Age         City\n",
      "a    Alice  25.0     New York\n",
      "b      Bob  30.0  Los Angeles\n",
      "c  Charlie  35.0      Chicago\n"
     ]
    }
   ],
   "source": [
    "# pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "'''\n",
    "data:DataFrame 的数据部分,可以是字典、二维数组、Series、DataFrame 或其他可转换为 DataFrame 的对象.如果不提供此参数,则创建一个空的 DataFrame.\n",
    "index:DataFrame 的行索引,用于标识每行数据.可以是列表、数组、索引对象等.如果不提供此参数,则创建一个默认的整数索引.\n",
    "columns:DataFrame 的列索引,用于标识每列数据.可以是列表、数组、索引对象等.如果不提供此参数,则创建一个默认的整数索引.\n",
    "dtype:指定 DataFrame 的数据类型.可以是 NumPy 的数据类型,例如 np.int64、np.float64 等.如果不提供此参数,则根据数据自动推断数据类型.\n",
    "copy:是否复制数据.默认为 False,表示不复制数据.如果设置为 True,则复制输入的数据.\n",
    "'''\n",
    "\n",
    "#用列表创建DataFrame\n",
    "data = [['Google', 10], ['Runoob', 12], ['Wiki', 13]]\n",
    "# 不管是列索引(columns)还是行索引(index),只要没有在参数中定义，自动设置为range(n)\n",
    "df1 = pd.DataFrame(data, columns=['Site', 'Age'])\n",
    "print(df1)\n",
    "print('--------------')\n",
    "\n",
    "# 用字典创建DataFrame\n",
    "data = {'Site':['Google', 'Runoob', 'Wiki'], 'Age':[10, 12, 13]}\n",
    "# 字典的键为列索引(columns),字典的值为数据，行索引需要指定，否则自动设置为range(n)\n",
    "df2 = pd.DataFrame(data)\n",
    "print (df2)\n",
    "print('--------------')\n",
    "\n",
    "# 用ndarray创建DataFrame\n",
    "ndarray_data = np.array([\n",
    "    ['Google', 10],\n",
    "    ['Runoob', 12],\n",
    "    ['Wiki', 13]\n",
    "])\n",
    "# 和列表一样，外层为列,内层的为行\n",
    "df3 = pd.DataFrame(ndarray_data, columns=['Site', 'Age'])\n",
    "print(df3)\n",
    "print('--------------')\n",
    "\n",
    "# 用Series创建DataFrame\n",
    "s1 = pd.Series(['Alice', 'Bob', 'Charlie'],index=['a','b','c'])\n",
    "# Series自带了行索引(index)，可以指定列索引(columns)\n",
    "s2 = pd.Series([25, 30, 35],index=['a','b','c'])\n",
    "s3 = pd.Series(['New York', 'Los Angeles', 'Chicago'],index=['a','b','c'])\n",
    "df4 = pd.DataFrame({'Name': s1, 'Age': s2, 'City': s3})\n",
    "df4['Name'] = df4['Name'].astype(str)\n",
    "df4['Age'] = df4['Age'].astype(float)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame的访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a      Alice\n",
      "b        Bob\n",
      "c    Charlie\n",
      "Name: Name, dtype: object\n",
      "--------------\n",
      "Name       Alice\n",
      "Age         25.0\n",
      "City    New York\n",
      "Name: a, dtype: object\n",
      "--------------\n",
      "Name       Alice\n",
      "Age         25.0\n",
      "City    New York\n",
      "Name: a, dtype: object\n",
      "--------------\n",
      "      Name   Age\n",
      "a    Alice  25.0\n",
      "b      Bob  30.0\n",
      "c  Charlie  35.0\n",
      "--------------\n",
      "a      Alice\n",
      "b        Bob\n",
      "c    Charlie\n",
      "Name: Name, dtype: object\n",
      "--------------\n",
      "      Name   Age\n",
      "b      Bob  30.0\n",
      "c  Charlie  35.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DataFrame访问列时直接用列名，访问行时用iloc和loc，其中iloc是按位置访问，loc是按标签访问\n",
    "print(df4['Name'])\n",
    "print('--------------')\n",
    "print(df4.loc['a'])\n",
    "print('--------------')\n",
    "print(df4.iloc[0])\n",
    "print('--------------')\n",
    "\n",
    "# DataFrame的切片\n",
    "# DataFrame行切片时用iloc和loc，其中iloc是按位置切片，loc是按标签切片\n",
    "# DataFrame不能先切列再切片行，只能先切片行再切片列\n",
    "# 如果使用loc，行和列都只能用标签值，不能用位置值\n",
    "# 如果使用iloc，行和列都只能用位置值，不能用标签值\n",
    "print(df4[['Name', 'Age']])  # 提取多列\n",
    "print('--------------')\n",
    "# print(df4[1:3])              #切片建议使用loc和iloc，这个语法的切片在写整数时是按行切片，在写字符串列表时是按列切片，不规范\n",
    "# print('--------------')\n",
    "print(df4.loc[:, 'Name'])     # 提取单列\n",
    "print('--------------')\n",
    "print(df4.iloc[1:3, [0, 1]])  # 使用.iloc和整数来提取指定行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame的常用属性和方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "Index(['Name', 'Age', 'City'], dtype='object')\n",
      "Index(['a', 'b', 'c'], dtype='object')\n",
      "Name     object\n",
      "Age     float64\n",
      "City     object\n",
      "dtype: object\n",
      "--------------\n",
      "      Name   Age         City\n",
      "a    Alice  25.0     New York\n",
      "b      Bob  30.0  Los Angeles\n",
      "c  Charlie  35.0      Chicago\n",
      "--------------\n",
      "      Name   Age         City\n",
      "a    Alice  25.0     New York\n",
      "b      Bob  30.0  Los Angeles\n",
      "c  Charlie  35.0      Chicago\n",
      "--------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, a to c\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Name    3 non-null      object \n",
      " 1   Age     3 non-null      float64\n",
      " 2   City    3 non-null      object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "--------------\n",
      "        Age\n",
      "count   3.0\n",
      "mean   30.0\n",
      "std     5.0\n",
      "min    25.0\n",
      "25%    27.5\n",
      "50%    30.0\n",
      "75%    32.5\n",
      "max    35.0\n",
      "--------------\n",
      "30.0\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# DataFrame的属性\n",
    "print(df4.shape)     # 形状\n",
    "print(df4.columns)   # 列名\n",
    "print(df4.index)     # 索引\n",
    "print(df4.dtypes)    # 数据类型\n",
    "print('--------------')\n",
    "\n",
    "\n",
    "# DataFrame的常用方法\n",
    "print(df4.head())    # 前几行数据,默认是前 5 行\n",
    "print('--------------')\n",
    "print(df4.tail())    # 后几行数据,默认是后 5 行\n",
    "print('--------------')\n",
    "print(df4.info())    # 数据信息\n",
    "print('--------------')\n",
    "print(df4.describe())# 描述信息\n",
    "print('--------------')\n",
    "print(df4['Age'].mean())    # 求平均值\n",
    "print(df4['Age'].sum())     # 求和\n",
    "\n",
    "'''\n",
    "1. 转换操作\n",
    "df.transpose(): 转置 DataFrame,行变成列,列变成行。\n",
    "df.melt(): 将 DataFrame 从宽格式转换为长格式。\n",
    "df.pivot(): 根据 DataFrame 中的值重建索引,类似于 Excel 中的数据透视表。\n",
    "2. 缺失值处理\n",
    "df.dropna(): 删除含有缺失值的行或列。\n",
    "df.fillna(): 用指定值填充缺失值。\n",
    "df.isna(): 检测缺失值,返回布尔型 DataFrame。\n",
    "df.notna(): 检测非缺失值,返回布尔型 DataFrame。\n",
    "3. 填充方法\n",
    "df.ffill(): 向前填充,用前一个非NaN值填充NaN值。\n",
    "df.bfill(): 向后填充,用后一个非NaN值填充NaN值。\n",
    "4. 数据重塑\n",
    "df.stack(): 将列索引转换为行索引,降低维度。\n",
    "df.unstack(): 将行索引转换为列索引,提升维度。\n",
    "df.droplevel(): 删除 MultiIndex 中的某个级别。\n",
    "5. 数据排序\n",
    "df.sort_values(): 根据 DataFrame 的列值进行排序。\n",
    "df.sort_index(): 根据 DataFrame 的索引进行排序。\n",
    "6. 数据选择\n",
    "df.loc[]: 通过索引标签进行数据选择。\n",
    "df.iloc[]: 通过索引位置进行数据选择。\n",
    "df.at[]: 通过标签快速访问单个标量。\n",
    "df.iat[]: 通过位置快速访问单个标量。\n",
    "7. 数据合并\n",
    "pd.concat(): 沿着一条轴将多个对象堆叠到一起。\n",
    "df.append(): 将其他 DataFrame 添加到当前 DataFrame 的末尾。\n",
    "pd.merge(): 根据 DataFrame 的一个或多个键将不同的 DataFrame 合并在一起。\n",
    "8. 数据聚合\n",
    "df.groupby(): 对 DataFrame 中的数据进行分组,并应用函数。\n",
    "df.agg(): 对 DataFrame 中的列应用一个或多个聚合函数。\n",
    "df.transform(): 对 DataFrame 中的数据进行转换,返回与原始数据相同形状的结果。\n",
    "9. 数据统计描述\n",
    "df.describe(): 计算各列的基本统计信息。\n",
    "df.count(): 计算非空值的数量。\n",
    "df.max(), df.min(): 计算最大值和最小值。\n",
    "df.mean(), df.median(): 计算平均值和中位数。\n",
    "10. 数据复制\n",
    "df.copy(): 复制 DataFrame 的数据。\n",
    "这些方法涵盖了从数据预处理、数据操作到数据分析的多个方面,是处理 pandas DataFrame 时经常使用的工具。\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame的修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age      City\n",
      "a  Jack  25.0  New York\n",
      "b   Tom  24.0   beijing\n",
      "c  Mike  35.0   Chicago\n",
      "--------------\n",
      "   Name   Age      City\n",
      "a  Jack  25.0  New York\n",
      "b   Tom  24.0   beijing\n",
      "c  Mike  35.0   Chicago\n",
      "--------------\n",
      "   Name   Age      City\n",
      "a  Jack  25.0  New York\n",
      "b  Lucy  24.0   beijing\n",
      "c  Mike  35.0   Chicago\n",
      "--------------\n",
      "    Age      City\n",
      "a  25.0  New York\n",
      "b  24.0   beijing\n",
      "c  35.0   Chicago\n",
      "--------------\n",
      "   Name   Age      City\n",
      "a  Jack  25.0  New York\n",
      "c  Mike  35.0   Chicago\n",
      "--------------\n",
      "   Name   Age     City\n",
      "c  Mike  35.0  Chicago\n"
     ]
    }
   ],
   "source": [
    "# 单个元素的修改\n",
    "\n",
    "# 使用二维索引定位后修改\n",
    "df4.loc['b','Name'] = 'Tom'\n",
    "print(df4)\n",
    "print('--------------')\n",
    "\n",
    "\n",
    "\n",
    "# 整行/列的修改\n",
    "\n",
    "# 整行的修改\n",
    "df4.loc['b'] = ['Tom',24,'beijing']\n",
    "print(df4)\n",
    "print('--------------')\n",
    "# 整列的修改\n",
    "df4['Name'] = ['Jack','Lucy','Mike']\n",
    "print(df4)\n",
    "print('--------------')\n",
    "\n",
    "# 元素的删除 DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
    "\n",
    "# 删除列\n",
    "df4_removecolumn=df4.drop('Name',axis=1)\n",
    "print(df4_removecolumn)\n",
    "print('--------------')\n",
    "# 删除行\n",
    "df4_removeindex=df4.drop('b')\n",
    "print(df4_removeindex)\n",
    "print('--------------')\n",
    "# 删除多行(删除多列类似)\n",
    "df4_removemultipleindex=df4.drop(['a','b'])\n",
    "print(df4_removemultipleindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age      City\n",
      "A  Jack  25.0  New York\n",
      "B  Lucy  24.0   beijing\n",
      "C  Mike  35.0   Chicago\n",
      "--------------\n",
      "   Name   Age   Address\n",
      "A  Jack  25.0  New York\n",
      "B  Lucy  24.0   beijing\n",
      "C  Mike  35.0   Chicago\n",
      "--------------\n",
      "Info  Name   Age   Address\n",
      "No.                       \n",
      "A     Jack  25.0  New York\n",
      "B     Lucy  24.0   beijing\n",
      "C     Mike  35.0   Chicago\n",
      "--------------\n",
      "Info  Name   Age   Address\n",
      "0     Jack  25.0  New York\n",
      "1     Lucy  24.0   beijing\n",
      "2     Mike  35.0   Chicago\n",
      "Info      Name   Age\n",
      "Address             \n",
      "New York  Jack  25.0\n",
      "beijing   Lucy  24.0\n",
      "Chicago   Mike  35.0\n"
     ]
    }
   ],
   "source": [
    "#修改index和columns\n",
    "\n",
    "#修改index\n",
    "df4.index = ['A','B','C']\n",
    "print(df4)\n",
    "print('--------------')\n",
    "#修改columns\n",
    "df4.columns = ['Name','Age','Address']\n",
    "print(df4)\n",
    "print('--------------')\n",
    "#修改index和columns的名称/默认为None\n",
    "df4.index.name = 'No.'\n",
    "df4.columns.name = 'Info'\n",
    "print(df4)\n",
    "print('--------------')\n",
    "\n",
    "\n",
    "\n",
    "# 重置和更换index\n",
    "df_reset = df4.reset_index(drop=True)\n",
    "print(df_reset)\n",
    "# 将一列设置为index，类似于数据库的更换主键\n",
    "df_set = df_reset.set_index('Address')\n",
    "print(df_set)\n",
    "\n",
    "\n",
    "\n",
    "# 转换列的类型\n",
    "df4['Address'] = df4['Address'].astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Site  Age\n",
      "one    Google   10\n",
      "two    Runoob   12\n",
      "three    Wiki   13\n",
      "--------------\n",
      "         Site  Age\n",
      "one    Google   10\n",
      "two    Runoob   12\n",
      "three    Wiki   13\n",
      "--------------\n",
      "         Site  Age\n",
      "one    Google   10\n",
      "two    Runoob   12\n",
      "three    Wiki   13\n",
      "one    Google   10\n",
      "two    Runoob   12\n",
      "three    Wiki   13\n",
      "--------------\n",
      "     Site  Age\n",
      "0  Google   10\n",
      "1  Runoob   12\n",
      "2    Wiki   13\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 合并\n",
    "\n",
    "\n",
    "data = [['Google', 10], ['Runoob', 12], ['Wiki', 13]]\n",
    "df1 = pd.DataFrame(data, columns=['Site', 'Age'],index=['one', 'two', 'three'])\n",
    "print(df1)\n",
    "print('--------------')\n",
    "data = {'Site':['Google', 'Runoob', 'Wiki'], 'Age':[10, 12, 13]}\n",
    "df2 = pd.DataFrame(data,index=['one', 'two', 'three'])\n",
    "print (df2)\n",
    "print('--------------')\n",
    "\n",
    "\n",
    "\n",
    "# 纵向合并\n",
    "# 如果默认索引相同，纵向合并可以智能调整\n",
    "# ignore_index=True, 会重新设置索引,否则可能会出现重复索引\n",
    "print(pd.concat(objs=[df1, df2], axis=0, join='outer', ignore_index=True))\n",
    "print('--------------')\n",
    "# 横向合并\n",
    "print(pd.merge(df1, df2, on=None)) #on默认为None，就是自然连接，相同的列会合并，如果on设置为一个列，只有这个列会被合并\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Subject  Score\n",
      "0    Alice     Math     90\n",
      "1      Bob     Math     85\n",
      "2  Charlie  Science     95\n",
      "3    David  Science     80\n",
      "--------------\n",
      "Pivot 结果：\n",
      "Subject  Math  Science\n",
      "Name                  \n",
      "Alice    90.0      NaN\n",
      "Bob      85.0      NaN\n",
      "Charlie   NaN     95.0\n",
      "David     NaN     80.0\n",
      "--------------\n",
      "Melt 结果：\n",
      "      Name  Subject  score\n",
      "0    Alice     Math   90.0\n",
      "1      Bob     Math   85.0\n",
      "2  Charlie     Math    NaN\n",
      "3    David     Math    NaN\n",
      "4    Alice  Science    NaN\n",
      "5      Bob  Science    NaN\n",
      "6  Charlie  Science   95.0\n",
      "7    David  Science   80.0\n"
     ]
    }
   ],
   "source": [
    "# 数据透视和数据逆透视\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Subject': ['Math', 'Math', 'Science', 'Science'],\n",
    "    'Score': [90, 85, 95, 80]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print('--------------')\n",
    "# 使用 pivot 函数将长格式转换为宽格式(有点像把表按columns(指的是这个函数里的参数)进行分组，columns的每一个取值为一个新列)\n",
    "df_pivot = df.pivot(index='Name', columns='Subject', values='Score')\n",
    "print(\"Pivot 结果：\")\n",
    "print(df_pivot)\n",
    "print('--------------')\n",
    "# 使用 melt 函数将宽格式转换为长格式(把除了id_vars和value_name的列合并起来,类名变为var_name)\n",
    "df_melt = df_pivot.reset_index().melt(id_vars='Name', value_name='score', var_name='Subject')\n",
    "print(\"Melt 结果：\")\n",
    "print(df_melt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用pandas进行数据清洗\n",
    "处理数据缺失、数据格式错误、错误数据或重复数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义什么是空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PID  ST_NUM     ST_NAME OWN_OCCUPIED NUM_BEDROOMS NUM_BATH SQ_FT\n",
      "0  100001000.0   104.0      PUTNAM            Y            3        1  1000\n",
      "1  100002000.0   197.0   LEXINGTON            N            3      1.5    --\n",
      "2  100003000.0     NaN   LEXINGTON            N          NaN        1   850\n",
      "3  100004000.0   201.0    BERKELEY           12            1      NaN   700\n",
      "4          NaN   203.0    BERKELEY            Y            3        2  1600\n",
      "5  100006000.0   207.0    BERKELEY            Y          NaN        1   800\n",
      "6  100007000.0     NaN  WASHINGTON          NaN            2   HURLEY   950\n",
      "7  100008000.0   213.0     TREMONT            Y            1        1   NaN\n",
      "8  100009000.0   215.0     TREMONT            Y           na        2  1800\n",
      "-------------------------------\n",
      "           PID  ST_NUM     ST_NAME OWN_OCCUPIED  NUM_BEDROOMS NUM_BATH   SQ_FT\n",
      "0  100001000.0   104.0      PUTNAM            Y           3.0        1  1000.0\n",
      "1  100002000.0   197.0   LEXINGTON            N           3.0      1.5     NaN\n",
      "2  100003000.0     NaN   LEXINGTON            N           NaN        1   850.0\n",
      "3  100004000.0   201.0    BERKELEY           12           1.0      NaN   700.0\n",
      "4          NaN   203.0    BERKELEY            Y           3.0        2  1600.0\n",
      "5  100006000.0   207.0    BERKELEY            Y           NaN        1   800.0\n",
      "6  100007000.0     NaN  WASHINGTON          NaN           2.0   HURLEY   950.0\n",
      "7  100008000.0   213.0     TREMONT            Y           1.0        1     NaN\n",
      "8  100009000.0   215.0     TREMONT            Y           NaN        2  1800.0\n"
     ]
    }
   ],
   "source": [
    "# 示例文件property-data.csv中包含的空数据有四种：n/a  NA  --  na\n",
    "df = pd.read_csv('property-data.csv')\n",
    "print(df)\n",
    "print('-------------------------------')\n",
    "# 可以看到n/a和NA都被识别为了空数据,成了NAN,而--和na没有被识别None,修改的是源数据\n",
    "# 要定义什么是空数据,就要用到na_values参数\n",
    "zero_values = [\"na\", \"--\"]\n",
    "df1 = pd.read_csv('property-data.csv', na_values = zero_values)\n",
    "# read_csv函数会将n/a和NA都识别为空值,na_values中是用户定义的额外的空值\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清洗空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "只有一行没有空值\n",
      "           PID  ST_NUM ST_NAME OWN_OCCUPIED  NUM_BEDROOMS NUM_BATH   SQ_FT\n",
      "0  100001000.0   104.0  PUTNAM            Y           3.0        1  1000.0\n",
      "-------------------------------\n",
      "只有 ST_NAME这一列没有空值\n",
      "      ST_NAME\n",
      "0      PUTNAM\n",
      "1   LEXINGTON\n",
      "2   LEXINGTON\n",
      "3    BERKELEY\n",
      "4    BERKELEY\n",
      "5    BERKELEY\n",
      "6  WASHINGTON\n",
      "7     TREMONT\n",
      "8     TREMONT\n",
      "-------------------------------\n",
      "ST_NUM这一列有两个空值,所以删除了两行\n",
      "           PID  ST_NUM    ST_NAME OWN_OCCUPIED  NUM_BEDROOMS NUM_BATH   SQ_FT\n",
      "0  100001000.0   104.0     PUTNAM            Y           3.0        1  1000.0\n",
      "1  100002000.0   197.0  LEXINGTON            N           3.0      1.5     NaN\n",
      "3  100004000.0   201.0   BERKELEY           12           1.0      NaN   700.0\n",
      "4          NaN   203.0   BERKELEY            Y           3.0        2  1600.0\n",
      "5  100006000.0   207.0   BERKELEY            Y           NaN        1   800.0\n",
      "7  100008000.0   213.0    TREMONT            Y           1.0        1     NaN\n",
      "8  100009000.0   215.0    TREMONT            Y           NaN        2  1800.0\n",
      "-------------------------------\n",
      "ST_NUM这一列有两个空值,所以删除了两行\n",
      "           PID     ST_NAME OWN_OCCUPIED NUM_BATH   SQ_FT\n",
      "0  100001000.0      PUTNAM            Y        1  1000.0\n",
      "1  100002000.0   LEXINGTON            N      1.5     NaN\n",
      "2  100003000.0   LEXINGTON            N        1   850.0\n",
      "3  100004000.0    BERKELEY           12      NaN   700.0\n",
      "4          NaN    BERKELEY            Y        2  1600.0\n",
      "5  100006000.0    BERKELEY            Y        1   800.0\n",
      "6  100007000.0  WASHINGTON          NaN   HURLEY   950.0\n",
      "7  100008000.0     TREMONT            Y        1     NaN\n",
      "8  100009000.0     TREMONT            Y        2  1800.0\n"
     ]
    }
   ],
   "source": [
    "# 删除带有空值的行/列\n",
    "\n",
    "\n",
    "# DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "'''\n",
    "axis: 默认为 0,表示逢空值剔除整行,如果设置参数 axis=1 表示逢空值去掉整列。\n",
    "how: 默认为 'any' 如果一行（或一列）里任何一个数据有出现 NA 就去掉整行,如果设置 how='all' 一行（或列）都是 NA 才去掉这整行。\n",
    "thresh: 设置需要多少非空值的数据才可以保留下来的。\n",
    "subset: 如果axis=0，设置想要检查的列。如果是多个列,可以使用列名的 list 作为参数。\n",
    "inplace: 如果设置 True,将计算得到的值直接覆盖之前的值并返回 None,修改的是源数据。\n",
    "'''\n",
    "# 删除有空值的列\n",
    "new_df1 = df1.dropna()\n",
    "print('只有一行没有空值')\n",
    "print(new_df1)\n",
    "print('-------------------------------')\n",
    "\n",
    "# 删除有空值的行\n",
    "new_df2 = df1.dropna(axis=1)\n",
    "print('只有 ST_NAME这一列没有空值')\n",
    "print(new_df2)\n",
    "print('-------------------------------')\n",
    "\n",
    "# 根据特定列有没有空值删除行\n",
    "new_df3=df1.dropna(subset=['ST_NUM'])\n",
    "print('ST_NUM这一列有两个空值,所以删除了两行')\n",
    "print(new_df3)\n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# 根据特定行有没有空值删除列\n",
    "new_df4=df1.dropna(axis=1,subset=[2])\n",
    "print('2这一行有两个空值,所以删除了两列')\n",
    "print(new_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1000.0\n",
      "1    1000.0\n",
      "2     850.0\n",
      "3     700.0\n",
      "4    1600.0\n",
      "5     800.0\n",
      "6     950.0\n",
      "7     950.0\n",
      "8    1800.0\n",
      "Name: SQ_FT, dtype: float64\n",
      "-------------------------------\n",
      "0    1000.0\n",
      "1    1100.0\n",
      "2     850.0\n",
      "3     700.0\n",
      "4    1600.0\n",
      "5     800.0\n",
      "6     950.0\n",
      "7    1100.0\n",
      "8    1800.0\n",
      "Name: SQ_FT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 替换空值\n",
    "\n",
    "# DataFrame.fillna(value=None, method=None, axis=0, inplace=False, limit=None, downcast=None)\n",
    "'''\n",
    "value:用于填充缺失值的值。可以是标量、字典、Series或DataFrame。如果是字典,可以针对不同的列指定不同的填充值。\n",
    "method:用于填充缺失值的方法。对于时间序列数据,可以是 'ffill'（前向填充,即用前面的非空值填充后面的空值）或 'bfill'（后向填充,即用后面的非空值填充前面的空值）。!!这个参数不久后会弃用,直接用df.bfill和df.ffill方法\n",
    "axis:指定填充的轴。0 或 'index' 表示按行填充,1 或 'columns' 表示按列填充。主要是配合method参数和value参数使用\n",
    "inplace:如果为True,则在原DataFrame上进行操作,不返回新的DataFrame。\n",
    "limit:如果指定了方法,这是连续填充的最大数量。在达到这个限制后,剩余的缺失值将不会被填充。\n",
    "downcast:尝试将数据转换为更小的数据类型（如果可能）。\n",
    "'''\n",
    "\n",
    "# 对df1的SQ_FT列进行前向填充\n",
    "df1_SQFT_ffill=df1['SQ_FT'].ffill()\n",
    "print(df1_SQFT_ffill)\n",
    "print('-------------------------------')\n",
    "\n",
    "# mean(),median() 和 mode() 方法计算列的均值、中位数值和众数进行替换。\n",
    "# 以对SQ_FT列进行均值填充为例\n",
    "df1_SQFT_meanfill=df1['SQ_FT'].fillna(df1['SQ_FT'].mean())\n",
    "print(df1_SQFT_meanfill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "datetime64[ns]\n",
      "           Date  duration\n",
      "day1 2020-12-01        50\n",
      "day2 2020-12-02        40\n",
      "day3 2020-12-26        45\n",
      "     name  age\n",
      "0  Google   50\n",
      "1  Runoob  120\n",
      "2  Taobao  120\n"
     ]
    }
   ],
   "source": [
    "# 处理错误数据(删除或替换)\n",
    "\n",
    "\n",
    "# 日期格式错误\n",
    "# pd.to_datetime函数是将数据转换为日期格式\n",
    "data = {\n",
    "  \"Date\": ['2020/12/01', '2020/12/02' , '20201226'],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "\n",
    "df_date = pd.DataFrame(data, index = [\"day1\", \"day2\", \"day3\"])\n",
    "# 日期格式错误\n",
    "print(df_date['Date'].dtype)\n",
    "df_date['Date'] = pd.to_datetime(df_date['Date'], format='mixed')\n",
    "# 修改后格式正确\n",
    "print(df_date['Date'].dtype)\n",
    "print(df_date.to_string())\n",
    "\n",
    "\n",
    "# 条件筛选错误数据并进行处理(单个值修改,整行删除等)\n",
    "person = {\n",
    "  \"name\": ['Google', 'Runoob' , 'Taobao'],\n",
    "  \"age\": [50, 200, 12345]    \n",
    "}\n",
    "\n",
    "df_age = pd.DataFrame(person)\n",
    "\n",
    "for x in df_age.index:\n",
    "  if df_age.loc[x, \"age\"] > 120:\n",
    "    #修改\n",
    "    df_age.loc[x, \"age\"] = 120\n",
    "    #整行删除\n",
    "    #df_age.drop(x, inplace = True)\n",
    "\n",
    "print(df_age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "----------------------------------------\n",
      "原数据\n",
      "     name  age\n",
      "0  Google   50\n",
      "1  Runoob   40\n",
      "2  Runoob   40\n",
      "3  Taobao   23\n",
      "去重后\n",
      "     name  age\n",
      "0  Google   50\n",
      "1  Runoob   40\n",
      "3  Taobao   23\n"
     ]
    }
   ],
   "source": [
    "# 处理重复数据\n",
    "\n",
    "\n",
    "# df.duplicated() 和 df.drop_duplicates()\n",
    "# df.duplicated() 方法返回一个布尔类型的 Series 对象，表示每一行是否为重复行。\n",
    "# df.drop_duplicates() 方法返回一个新的 DataFrame 对象，其中重复行被删除。\n",
    "\n",
    "\n",
    "person = {\n",
    "  \"name\": ['Google', 'Runoob', 'Runoob', 'Taobao'],\n",
    "  \"age\": [50, 40, 40, 23]  \n",
    "}\n",
    "df_person = pd.DataFrame(person)\n",
    "\n",
    "print(df_person.duplicated())\n",
    "print('----------------------------------------')\n",
    "print('原数据')\n",
    "print(df_person)\n",
    "print('去重后')\n",
    "print(df_person.drop_duplicates())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
